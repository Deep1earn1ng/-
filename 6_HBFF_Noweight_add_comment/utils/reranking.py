import torch
import numpy as np
import gc


def re_ranking(qf, gf, k1=20, k2=6, lambda_value=0.3):
    """
    [GPUåŠ é€Ÿ + ä½å†…å­˜ä¼˜åŒ–ç‰ˆ] k-reciprocal re-ranking

    é’ˆå¯¹ç¡¬ä»¶: RTX 4070Ti (12GB VRAM) + 32GB/40GB System RAM
    é’ˆå¯¹æ•°æ®: MSMT17 (93k samples)

    ç­–ç•¥:
    1. ç‰¹å¾å¸¸é©» GPU (ä»…çº¦ 300MB)ã€‚
    2. GPU åˆ†å—è®¡ç®—æ¬§æ°è·ç¦»å¹¶ Top-K æ’åº (åˆ©ç”¨ 4070Ti ç®—åŠ›ï¼Œé€Ÿåº¦æå¿«)ã€‚
    3. CPU æ¥æ”¶ Top-K ç»“æœï¼Œä½¿ç”¨ Float16 æ„å»ºç¨€ç–å›¾ (è§£å†³å†…å­˜ç“¶é¢ˆ)ã€‚
    """
    # 1. è®¾ç½®è®¾å¤‡ï¼šä¼˜å…ˆä½¿ç”¨ GPU åŠ é€Ÿ
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"  [Re-Ranking] ğŸš€ å¯ç”¨ GPU åˆ†å—åŠ é€Ÿæ¨¡å¼ (åˆ©ç”¨ {torch.cuda.get_device_name(0)})...")
    else:
        device = torch.device('cpu')
        print("  [Re-Ranking] æœªæ£€æµ‹åˆ° GPUï¼Œå›é€€åˆ° CPU æ¨¡å¼...")

    # 2. æ•°æ®è½¬æ¢
    if isinstance(qf, np.ndarray): qf = torch.from_numpy(qf)
    if isinstance(gf, np.ndarray): gf = torch.from_numpy(gf)

    num_query = qf.shape[0]
    num_gallery = gf.shape[0]
    num_total = num_query + num_gallery

    # å°†æ‰€æœ‰ç‰¹å¾ä¸€æ¬¡æ€§ä¸Šä¼ åˆ° GPU (MSMT17 ç‰¹å¾ä»…çº¦ 300MBï¼Œéå¸¸å®‰å…¨)
    # ä½¿ç”¨ float32 ä¿è¯ç²¾åº¦
    feat = torch.cat([qf, gf], dim=0).to(device)

    print(f"  [1/5] GPU åˆ†å—è®¡ç®—æ¬§æ°è·ç¦» & Top-K (N={num_total})...")

    # 3. é¢„åˆ†é… CPU å†…å­˜ç”¨äºå­˜å‚¨ç»“æœ
    # 3.1 ä»…å­˜å‚¨ Query å¯¹ Gallery çš„å®Œæ•´è·ç¦» (ç”¨äºæœ€ç»ˆèåˆ)
    #     Size: 11659 * 82161 * 4 bytes â‰ˆ 3.6 GB (CPU RAM)
    original_dist_q2g = torch.zeros(num_query, num_gallery, dtype=torch.float32)

    # 3.2 å­˜å‚¨ Top-K ç´¢å¼•å’Œè·ç¦» (æ›¿ä»£å®Œæ•´çš„ NxN çŸ©é˜µ)
    #     Size: 93820 * 50 * 4 bytes â‰ˆ 18 MB (æå°)
    #     åªéœ€è¦ k1+1 ä¸ªé‚»å±…ï¼Œå¤šå­˜ä¸€ç‚¹ä½™é‡é˜²æ­¢è¾¹ç•Œæ•ˆåº”
    search_k = max(k1 + 10, 50)
    initial_rank = torch.zeros(num_total, search_k, dtype=torch.int32)
    initial_dist = torch.zeros(num_total, search_k, dtype=torch.float32)

    # 4. GPU åˆ†å—è®¡ç®—å¾ªç¯
    # æ˜¾å­˜å ç”¨ä¼°ç®—:
    # block_size=4096 -> è·ç¦»çŸ©é˜µ 4096 * 93820 * 4 bytes â‰ˆ 1.5 GB
    # åŠ ä¸Šä¸­é—´å˜é‡ï¼Œ12GB æ˜¾å­˜ç»°ç»°æœ‰ä½™
    block_size = 4096

    # é¢„å…ˆè®¡ç®—æ‰€æœ‰ç‰¹å¾çš„å¹³æ–¹å’Œ (x^2)ï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤è®¡ç®—
    # x_norm: [N, 1]
    all_x_norm = torch.pow(feat, 2).sum(dim=1, keepdim=True)

    for i in range(0, num_total, block_size):
        # æ‰“å°è¿›åº¦
        if i % (block_size * 2) == 0:
            print(f"   -> Processing batch {i}/{num_total}...")

        end = min(i + block_size, num_total)

        # å–å‡ºå½“å‰å—çš„ç‰¹å¾: [B, D]
        feat_block = feat[i:end, :]
        x_norm_block = all_x_norm[i:end, :]

        # --- GPU è®¡ç®—æ ¸å¿ƒåŒºåŸŸ ---
        # dist^2 = x^2 + y^2 - 2xy
        # y^2 å°±æ˜¯ all_x_norm.t()

        # 1. çŸ©é˜µä¹˜æ³• -2xy: [B, N]
        dist_block = torch.addmm(all_x_norm.t(), feat_block, feat.t(), beta=1, alpha=-2)

        # 2. åŠ ä¸Š x^2
        dist_block.add_(x_norm_block)

        # 3. å¼€æ ¹å· (Clamp é˜²æ­¢ NaN)
        dist_block = dist_block.clamp(min=1e-12).sqrt()

        # --- æ•°æ®å›ä¼ ä¸ä¿å­˜ ---

        # A. ä¿å­˜ Query-to-Gallery çš„è·ç¦» (ç”¨äºæœ€åä¸€æ­¥)
        # å¦‚æœå½“å‰å—å±äº Query éƒ¨åˆ†
        if i < num_query:
            valid_q_rows = min(end, num_query) - i
            if valid_q_rows > 0:
                # å¿…é¡» .cpu() å›ä¼ 
                original_dist_q2g[i:i + valid_q_rows, :] = \
                    dist_block[:valid_q_rows, num_query:].cpu()

        # B. GPU æ’åº (Top-K)
        # è¿™ä¸€æ­¥åœ¨ GPU ä¸Šæå¿«
        vals, idxs = torch.topk(dist_block, k=search_k, largest=False, dim=1)

        # C. å›ä¼  CPU å¹¶å­˜å‚¨
        initial_rank[i:end, :] = idxs.cpu().int()
        initial_dist[i:end, :] = vals.cpu().float()

        # æ¸…ç†ä¸´æ—¶å˜é‡
        del dist_block, vals, idxs

    # é‡Šæ”¾ GPU æ˜¾å­˜ (ç‰¹å¾ä¸å†éœ€è¦)
    del feat, all_x_norm
    torch.cuda.empty_cache()

    print("  [2/5] æ„å»ºç¨€ç–æƒé‡çŸ©é˜µ V (CPU Float16)...")

    # 5. åç»­é€»è¾‘å…¨éƒ¨åœ¨ CPU ä¸Šè¿›è¡Œ (é€»è¾‘åŒä¹‹å‰ï¼Œå†…å­˜ä¼˜åŒ–ç‰ˆ)
    # NxN Float16 çŸ©é˜µçº¦å  16.5 GB -> ç¡®ä¿ä½ æœ‰ 32GB+ å†…å­˜
    V = torch.zeros(num_total, num_total, dtype=torch.float16)

    for i in range(num_total):
        # åˆ©ç”¨ Top-K ç´¢å¼•å¿«é€Ÿæ„å»º
        forward_k1 = initial_rank[i, :k1 + 1]
        backward_k1 = initial_rank[forward_k1.long(), :k1 + 1]

        mask = (backward_k1 == i).any(dim=1)
        k_reciprocal_idx = forward_k1[mask].long()

        # è·å–å¯¹åº”è·ç¦»
        # åˆ©ç”¨ mask ä» initial_dist ä¸­ç­›é€‰
        dist_vals = initial_dist[i, :k1 + 1][mask]

        if dist_vals.numel() > 0:
            v_vals = torch.exp(-dist_vals)
            v_vals = v_vals / torch.sum(v_vals)
            V[i, k_reciprocal_idx] = v_vals.half()

    # 6. Query Expansion
    # æ³¨æ„ï¼šè¿™ä¸€æ­¥ä¼šåˆ›å»º V_qeï¼Œéœ€è¦é¢å¤–çš„ 16.5GB å†…å­˜ã€‚
    # æ€»å³°å€¼å†…å­˜ = 16.5(V) + 16.5(V_qe) + 3.6(Dist) â‰ˆ 36.6 GB
    # 40GB æ€»å†…å­˜åº”è¯¥åˆšå¥½èƒ½è·‘ (ä¼šç”¨åˆ° Swap)
    if k2 > 1:
        print("  [3/5] Query Expansion (High Memory Usage)...")
        try:
            V_qe = torch.zeros_like(V)
            for i in range(num_total):
                nbrs = initial_rank[i, :k2].long()
                V_qe[i, :] = torch.mean(V[nbrs, :].float(), dim=0).half()
            V = V_qe
            del V_qe
        except RuntimeError:
            print("  [Warning] å†…å­˜ä¸è¶³ï¼Œè·³è¿‡ Query Expansion æ­¥éª¤ã€‚")
            gc.collect()

    del initial_rank, initial_dist
    gc.collect()

    print("  [4/5] è®¡ç®— Jaccard è·ç¦»...")
    # 7. Jaccard Distance (CPU)
    # å»ºç«‹å€’æ’ç´¢å¼•åŠ é€Ÿ
    invIndex = []
    for i in range(num_total):
        invIndex.append(torch.nonzero(V[:, i]).squeeze(-1))

    jaccard_dist = torch.zeros(num_query, num_total, dtype=torch.float32)

    # è¿›åº¦æ¡
    for i in range(num_query):
        temp_min = torch.zeros(num_total, dtype=torch.float32)
        indNonZero = torch.nonzero(V[i, :]).squeeze(-1)

        for j in indNonZero:
            temp_ind = invIndex[j]
            # è®¡ç®— min(V[i,j], V[nodes, j])
            # æ³¨æ„ç±»å‹è½¬æ¢ float16 -> float32
            val_i = V[i, j].float()
            vals_nodes = V[temp_ind, j].float()
            temp_min[temp_ind] += torch.min(val_i, vals_nodes)

        jaccard_dist[i, :] = 1 - temp_min / (2. - torch.sum(V[i, :].float()))

    del V, invIndex
    gc.collect()

    print("  [5/5] æœ€ç»ˆèåˆ...")
    final_dist = jaccard_dist[:, num_query:] * (1 - lambda_value) + \
                 original_dist_q2g * lambda_value

    return final_dist.numpy()